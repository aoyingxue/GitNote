## 一. 数据挖掘
### 1. 实践意义上的学习
### 2. 解释数据并作出预测的工具
### 3. 解释算法的几个例子
----------------------------------
* ` 天气问题 WEATHER`
 	1. 天气有四个属性(outlook, temperature, humidity, windy)，结论是能否play
 	2. 属性值都是类别，而不是数值
 	3. 从已有列表结果中学习一组规则，这些规则按先后次序判断，称为==决策列表== (Decision List)
 	4. 分类规则(Classification Rule)：以是否能play去预测样本分类
 	5. 关联规则(Association Rule)：和不同的属性值紧密关联
 	6. 关联规则能够预测任何属性值，分类规则只能预测一个特定的类
***
* `隐形眼镜问题 CONTACT LENS`
    1. 通过患者年龄，患者眼睛情况，是否散光，眼泪的产生速率的比较，得出推荐的隐形眼镜的类型（hard,soft,none）
    2. 关于所有属性值的组合表
    3. 压缩海量数据库并通过==决策树==选择数据结构
***
* `鸢尾花 IRIS`
    1. 3个植物种类,50个样本,4个属性,==属性均为数值型==
    2. ==输出是类别==(类型),不是数值型

***
* `CPU性能 数值预测`
    1. 属性和输出均为==数值型==
    2. 处理连续预测值的传统方法:把结果写成一个线性属性值的和,并为每个属性加上适当的权值（回归公式 Regression Equation）
    3. 确定权值的过程称为回归
***
* `劳资协商`
    1. 按列的形式表示样本，有部分缺失，更加真实
    2. 更为复杂的决策树，健康计划和工作时间等同时影响决策，“好”的定义由工人和管理者共同决定，结构反映的是达成协议所要做的妥协。
    3. 虽然复杂的决策树更为准确，但在分析一个独立数据集时，性能可能降低，可能对数据“过度拟合”，需要对决策树进行剪枝
***
* ` 大豆分类 为诊断大豆疾病找出鉴别规则 `
  1. 大豆苗从35个属性被检测，样本由专家标记诊断结果（above normal/normal/same as last year/severe/...）
***

### 4.机器学习和统计学
统计学更加注重测试假说，机器学习更注重于规划出一个泛化的过程。
### 5.偏差
 1. 语言偏差 language bias
	 - 概念描述语言是否具有普遍性 / 是否在能够被学习到的概念上加了约束条件
	 - “通用”语言应该能够表示出==每个可能==的样本子集（理论上）
 2. 搜索偏差 search bias
	 - 搜索过程是启发式的，不能作出最终结果最优的保证
	 - 拟合（fit）：寻找一个与数据合理拟合的最佳描述
	 - “贪心”搜索规则（在每个阶段找出最好的规则，并加入规则集）时常有偏差，最好的一对规则并不是单独找出最好的然后叠加。
	 - 使用“束搜索（beam search）”：并行地寻求一个由多个动态替换方案组成的集合。替换方案的个数是束宽（beam width）。如果束宽不够打，短视依旧可能发生。
 3. 避免过度拟合偏差 overfitting-avoidance bias
	 1. 关于==逻辑或==的问题：
		如果允许包含逻辑或，在总结数据时会存在没有用的概念描述
		如果禁用逻辑或，一些概念将无法得到

	 2. 解决办法：从最简单的概念出发，逐渐复杂化。
		==前向剪枝/先剪枝（*forward pruning/prepruning*）== 由简到繁的搜索，在找到足够复杂的概念描述时停止
		==后向剪枝/后剪枝（*backward pruning/postpruning*）== 先找到与数据拟合很好的描述，然后向后剪枝，使之变成一个更简单的同样与数据拟合的描述

## 二. 数据输入
### 1. 相关概念
 1. 概念 concept
 2. 实例 instance：每个实例都是一个将要被学习的、独立的概念样本
 3. 属性 attribute
 4. 属性类型：数值属性 / 名目
 5. 概念描述 concept description：能够被学习的事物
 6. 可理解的 intelligible：能够被理解、商讨和辩论
 7. 可操作的 operational：能够被运用到实际的样本上
 8. 多类标实例 multilabeled instances：样本可能属于多个类别;应对方法：把它们当作几种不同的分类问题对待，每个对应一个可能的类别，相应问题是确定实例是否属于该类别
 9. ==分类学习/有监督学习 supervised==：学习方案是指导（每个训练样本都有一个明确的结论）下操作的，这些结论称为“==类==（*class*）”
 10. ==关联学习==：没有制定出特定的类，问题是如何从数据中找出“有趣的”结构。可以“预测”任何一个属性，不只是类，也可以一次预测一个以上的属性值。关联规则的数量远远多于分类规则，但要避免被过多的关联规则所困扰。所以，通常要为关联规则制定一个能够适用的最小样本率（如80%的数据集），还要大于一个特定的最小准确率（如95%），还必须手工验证它们是否具有意义。关联规则通常仅包含非数值型的属性。
 11. ==聚类==：找出聚类，并把实例分配到各个聚类上，还要能够将新的实例分配到相应的聚类上。聚类的成功与否通常以所得到的结论对人类使用者是否有用来主观地衡量。常伴随着分类学习，所学到的规则将给出如何把新的实例安置到相应聚类里的可以理解的描述。
 12. 数值预测：结论是一个数值，而不是分类。
### 2. 实例 Instances
 1. 输入是一个实例集，再由机器学习方案进行分类、关联或聚类。
 2. 实例集被称为==样本（example）==：每个实例都是被学习的单一独立的概念样本，由一组预先定义的属性值表示。
 3. 被表示成一个实例与属性的矩阵，用数据库的术语说这是单一关系或==平面文件（flat file）==。但这有局限性。实例之间通常有关系，并不是真正彼此分离、独立的，比如常用树形结构表示姐妹关系。
 4. **==封闭世界假定== closed-world assumption**：仅明确指出肯定样本且采用一个不变的假设（剩下的都是否定的样本）;理论上常用但不实用于现实。封闭世界意味着包含了所有事件，但实际中很少存在“封闭”的世界。
 5. **==反规则化== denormalization**：获取了两个关系，并把它们合并成一个。
    但有很多问题：①超级关系可以表示所有关系但是计算和存储代价太大 ②规律性虚假，只是原始数据库结构的再现。
 6. **祖先关系 ancestor-of** 等无限数据的现象在类似于列表处理及逻辑编程等领域却很常见。
    归纳逻辑编程 inductive logic programming:常使用递归进行处理，如不管两人关系有多远，都能用“祖先”这个递归定义来表示。但递归技术不善于处理噪声数据，
### 3. 属性 Attribute
 1. 每个单一独立的实例是由一组固定的和预先定义的特征或==属性==作为输入提供给机器学习的。一个固定特征集的使用是一种限制条件。
 2. 一种标准工作方法：把每个可能的特征作为一个属性，并使用一个“无关值”的标记指出对于一个特定的案例哪个属性不适用。当一个属性的存在（配偶的名字）取决于另一个属性值（已婚或未婚）的时候就会出现类似的情况。
 3. 一个特定实例的一个==属性值==：属性所对应的一个测量值



