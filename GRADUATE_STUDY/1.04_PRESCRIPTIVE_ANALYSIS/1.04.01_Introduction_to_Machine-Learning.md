## I. What is machine learning?

- Relationship between *Y<sub>i</sub> and X<sub>i</sub>*,

![image-20190826111731934](/Users/aoyingxue/Library/Application Support/typora-user-images/image-20190826111731934.png)

- **Goal** of Machine Learning: Estimate *f*,
- **Estimated** function is $\hat{f}$
- Other Names for Machine Learning: Statistical Learning, Data Mining, etc.
- Hope the random error not too big

- [x] ![image-20190826115709611](/Users/aoyingxue/Library/Application Support/typora-user-images/image-20190826115709611.png)

## II. Effects of Standard Deviation 

The **irreducible error**: The **variance** of random error 

The difficulty of estimating f will depend on the **standard deviation of the ε’s**.

## III. The Purpose of Machine Learning

- Estimate unknown (True) function *f*.
- Machine-Learning “<u>learns</u>” about *f* from data.
- **Why do we care about estimating** ***f***?
- 2 **reasons** for estimating *f*,
  - **Prediction**: forecast 
  - **Inference**: generalize the system

1. ### Prediction 

   1. **Good estimate for *f***
   2. **Variance of ε is not too large**
   3. Accurate predictions for the response, Y, based on a new value of X

2. ### Inference 

   1. Alternatively, we may also be interested in the type of relationship between Y and the X's.
   2. For example,
      1. **Which particular predictors actually affect the response**? 
      2. Is the relationship **positive or negative**? 
      3. Is the relationship a simple **linear one or is it more complicated** etc.?

### Example: Housing Inference

![image-20190826115527232](/Users/aoyingxue/Library/Application Support/typora-user-images/image-20190826115527232.png)

- Accurate in predicting
- But not good for inferences (because of the black box)

- [x] ![image-20190826115730505](/Users/aoyingxue/Library/Application Support/typora-user-images/image-20190826115730505.png)

- [ ] ![image-20190826115832885](/Users/aoyingxue/Library/Application Support/typora-user-images/image-20190826115832885.png)

## IV. Learning Methods

#### 1. How Do We Estimate f?

- Training data
  - ![image-20190826120124330](/Users/aoyingxue/Library/Application Support/typora-user-images/image-20190826120124330.png)
- **Use the training data** and **a learning method** to estimate *f*.
- Learning Methods:
  - **Parametric Methods (pre-determined structure)**
  - **Non-parametric Methods (flexible, algorithm allows any shape)**

#### 2. Parametric methods

- Shape is **predetermined**.

- To Estimate *f*, we estimate a set of parameters.

- They involve a two-step model based approach

  - STEP 1

    Make some **assumption about the functional form** of *f*, i.e. come up with a model. 

    Linear model i.e. (Linear regression)

    ![image-20190826120727932](/Users/aoyingxue/Library/Application Support/typora-user-images/image-20190826120727932.png)

  - STEP 2

    - Use training data to estimate *f* or equivalently the unknown **parameters** such as *β<sub>0</sub>*,*β<sub>1</sub>*,*β<sub>2</sub>*,…,*β*<sub>p</sub>.
    - Estimated Betas are "$\hat{β}_0,\hat{β}_1,\hat{β}_2,…,\hat{β}_p.$"
    - The most common approach for estimating the parameters in a linear model is ordinary least squares (OLS).
    - For the same data, we get the same estimate.

#### 3. Non-parametric methods

- No **assumptions about function** **form **of *f*.
- There are **tuning parameters**.
- <u>Advantages</u>: They **accurately fit** a wider range of possible shapes of f.
- <u>Disadvantages</u>: A very **large number of observations** is required to obtain an accurate estimate of f. They can also over fit the data. 
- Non-linear regression methods are **more flexible** and can potentially provide more accurate estimates. But sometimes it will fit for all the data but perform poorly to predict