

- Variables other than the treatment and outcome

#### THREE ROLES COVARIATES CAN PLAY WHEN MEASURING IMPACT

1. Increase statistical precision
   1. We have seen: blocking Today: multivariate regression

2. Checking randomization
3. “Bad controls”

## Regression for Experimental Analyses

<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd3ko28ebbj30tc0jy7bt.jpg" alt="image-20200322194841886" style="zoom:50%;" />

If t-value is larger than 1.96 (2), or p-value is smaller than 0.05, ATE estimate is statistically significant at the 5% level. 

##### R-Squared:

<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd3l4r2m8pj30vs0igwm5.jpg" alt="image-20200322200444283" style="zoom:50%;" />

Since students' past score is a strong predictor of their score in the current year, it means that some of the variations in the scores this year can be explained by variation in the scores from the past year. This means that if we can somehow control for students' score from the past, then that is going to reduce the chance difference in outcomes that is due to differences in students' score in the past year. 

##### Std. Error:

<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd46t4fa2dj30n60go79w.jpg" alt="image-20200323083436725" style="zoom:50%;" />

Note that this ATE estimate is slightly different than 1.2 that we got before, but given a standard error of 0.08, the difference in the two ATE estimates is only <u>one standard error</u> away from each other. This means that two ATE estimates are not statistically significantly different from each other. 

The rule of thumb to tell whether two estimates are statistically different from each other is to see whether the difference between the two estimates are more than twice the size of the largest standard error amounted to estimates. We will not derive this formally, but we will sometimes refers to this rule of thumb.

##### Add a covariate into regression (Covariate Adjustment)

![image-20200323084043505](https://tva1.sinaimg.cn/large/00831rSTgy1gd46zcp8xij30pw0hcjxx.jpg)

It's going to first fit two lines for the GPA this year as a function of GPA in the previous year. One line for the treatment group and the other line for the control group. Then the regression is going to compute the vertical distance between the two fitted lines.

![image-20200323084116489](https://tva1.sinaimg.cn/large/00831rSTgy1gd46zwzm8rj30uw0j0juo.jpg)

##### Summary: Adding Covariates To A Regression To Increase Precision

- PREDICT OUTCOMES
  - Variables that predict the outcome can be useful in increasing precision. Just add them to the regression. 
- OPTIONAL ENHANCEMENT
  - Adding covariates to a regression when evaluating experiments is an optional enhancement. We aren't "controlling for omitted variables" because we have **random assignment**.
    - We are not controlling for omitted variables because we have random assignment of the treatment status. We include this variables in the regression only to increase the efficiency of our estimate, which is to reduce the standard error of our estimate.
- SAME IN NON-EXPERIMENTS
  - When you analyze observational data, this principle applies as well.

## Real-World Example: Incentives for Public Services Delivery

## Second Role of Covariates: Randomization Checks

- Estimate “ATE” on variables that treatment cannot affect

> We basically regress different variables on the treatment status dummy and check whether there is a difference on these variables across the treatment and control groups. This procedure is as if we are trying to estimate some sort of ATE on variables that treatment cannot effect, and then we verify that the estimated coefficient in front of the treatment status is essentially 0, which means that these variables are indeed very similar across the treatment and control groups.

![image-20200323092857561](https://tva1.sinaimg.cn/large/00831rSTgy1gd48djakowj30ua0fm7c2.jpg)

![image-20200323093127617](https://tva1.sinaimg.cn/large/00831rSTgy1gd48g5fkfhj31000k043w.jpg)

## Third Role of Covariates: Bad Controls

### Bad Controls

- Other Outcome Variables
  - **When analyzing the results of an experiment,** **don’t** **include other outcome variables** **as covariates on the right-hand side of your regression.**

- Other outcome variables: anything that treatment could have affected.
- <u>Safe rule of thumb</u>: was it measured before treatment was administered? If so, it can’t be a bad control, because treatment can’t have affected it.
- Example: “Controlling For Occupation”
  - Suppose we estimate the returns to schooling by “controlling for occupation.”
  - But <u>schooling could also affect occupation</u>. If we want to know the returns to schooling, we should not include occupation on the right side. It is meaningless to talk about “the effects of schooling conditional on occupation,” because schooling can determine one’s occupation.
  - For example, if getting more school makes you more likely to become a plumber, and becoming a plumber makes you have a higher salary than you would if you had worked in a factory, then the total effect of schooling on earnings is much higher than “the returns to schooling conditional on becoming a plumber.”

- Another Example:
  - **We want to know whether having a higher eBay reputation causes us to earn more revenue on eBay. So we do an experiment with two eBay seller accounts, one of which has a higher reputation score than the other.**
    - When analyzing the results, one might be tempted to put “auction price” on the left side, and “number of bids” on the right side.
    - But number of bids would be a bad control.

## Summary: Role Of Covariates

![image-20200323093601269](https://tva1.sinaimg.cn/large/00831rSTgy1gd48kvdb2ij30v80fgq4y.jpg)

