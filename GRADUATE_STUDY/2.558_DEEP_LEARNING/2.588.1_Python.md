#### Formatted or interpolated string

You can mix strings and variables for printing. This technique is called a formatted or interpolated string. The variables must be inside of the curly braces. In Python, this type of string is generally called an f-string. The f-string is denoted by placing an "f" just in front of the opening single or double quote that begins the string. The following code demonstrates the use of an f-string to mix several variables with a literal string.

```python
a = 10
print(f'The value of a is {a}')

>>The value of a is 10
```

You can also use f-strings **with math** (called an expression). **Curly braces** can enclose any valid Python expression for printing. The following code demonstrates the use of an expression inside of the curly braces of an f-string.

```python
a = 10
print(f'The value of a plus 5 is {a+5}')

>>The value of a plus 5 is 15
```

```python
a = 5

print(f'a is {a}') # Preferred method for this course.
print('a is {}'.format(a))
print('a is ' + str(a))
print('a is %d' % (a))
```

### Categorical and Continuous Values

##### most basic ways to transform data for a neural network.

- Character Data (strings)
  - **Nominal** - Individual discrete items, no order. For example: color, zip code, shape.
  - **Ordinal** - Individual discrete items that can be ordered. For example: grade level, job title, Starbucks(tm) coffee size (tall, vente, grande)
- Numeric Data
  - **Interval** - Numeric values, no defined start. For example, temperature. You would never say "yesterday was twice as hot as today".
  - **Ratio** - Numeric values, clearly defined start. For example, speed. You would say that "The first car is going twice as fast as the second."

#### Encoding Continuous Values

##### Normalization 

One very common machine learning normalization is the Z-Score:

$z = \frac{x - \mu}{\sigma} $

To calculate the Z-Score you need to also calculate the mean($\mu$) and the standard deviation ($\sigma$). The mean is calculated as follows:

$\mu = \bar{x} = \frac{x_1+x_2+\cdots +x_n}{n}$

The standard deviation is calculated as follows:

$\sigma = \sqrt{\frac{1}{N} \sum_{i=1}^N (x*_i - \mu)^2}, {\rm \ \ where\ \ } \mu = \frac{1}{N} \sum_*{i=1}^N x_i$

The following Python code replaces the mpg with a z-score. Cars with average MPG will be near zero, above zero is above average, and below zero is below average. Z-Scores above/below -3/3 are very rare, these are outliers.

```python
from scipy.stats import zscore

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

df['mpg'] = zscore(df['mpg'])
display(df[0:5])
```



### Training and Validation

- **Training/Validation Split** - The data are split according to some ratio between a training and validation (hold-out) set. Common ratios are **80**% training and **20**% validation.

- **K-Fold Cross Validation** - The data are split into a number of folds and models. Because a number of models equal to the folds is created out-of-sample predictions can be generated for the entire dataset.

  ```python
  df = df.reindex(np.random.permutation(df.index)) # Usually a good idea to shuffle
  mask = np.random.rand(len(df)) < 0.8
  trainDF = pd.DataFrame(df[mask])
  validationDF = pd.DataFrame(df[~mask])
  ```

  

